# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #1 выполнил(а):
- Ланчу Елизавета Сергеевна
- ХИИ31
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Ознакомиться с основными операторами зыка Python на примере реализации линейной регрессии.

## Задание 1
### Написать программы Hello World на Python и Unity.

![2022-09-27_17-13-17](https://user-images.githubusercontent.com/81166835/192563873-fba9bf9c-3e87-4348-ad67-8c333b7a7d1e.png)

![2022-09-27_18-33-23](https://user-images.githubusercontent.com/81166835/192571298-21472011-8f5a-4610-8e83-d9efc8a9bcf3.png)

![2022-09-27_17-57-11](https://user-images.githubusercontent.com/81166835/192563927-2891d8e7-d02d-40d4-9b2e-04c0f8c32c6f.png)

![2022-09-27_17-56-47](https://user-images.githubusercontent.com/81166835/192563962-4b0513af-4d53-4f60-91c3-1a7e3fe05463.png)

## Задание 2
### Пошагово выполнить каждый пункт раздела "ход работы" с описанием и примерами реализации задач
Ход работы:
- Произвести подготовку данных для работы с алгоритмом линейной регрессии. 10 видов данных были установлены случайным образом, и данные находились в линейной зависимости. Данные преобразуются в формат массива, чтобы их можно было вычислить напрямую при использовании умножения и сложения.

![2022-09-25_13-57-29](https://user-images.githubusercontent.com/81166835/192153967-49e1a9d2-e9de-4bec-9d06-95aa5927ff9b.png)

- Определите связанные функции. Функция модели: определяет модель линейной регрессии wx+b. Функция потерь: функция потерь среднеквадратичной ошибки. Функция оптимизации: метод градиентного спуска для нахождения частных производных w и b.

![2022-09-25_20-19-07](https://user-images.githubusercontent.com/81166835/192156549-f3278ae3-8614-4c4f-9860-ffa34ccfedf7.png)

Начать итерацию
   - Шаг 1. Инициализация и модель итеративной оптимизации

![2022-09-25_21-40-15](https://user-images.githubusercontent.com/81166835/192161078-7ff610d7-9a06-4bc7-9110-23cab7e29edb.png)

   - Шаг 2 На второй итерации отображаются значения параметров, значения потерь и эффекты визуализации после итерации

![2022-09-25_21-40-23](https://user-images.githubusercontent.com/81166835/192161087-7750b6cc-5012-49e8-8172-781a765128cb.png)

   - Шаг 3 Третья итерация показывает значения параметров, значения потерь и визуализацию после итерации

![2022-09-25_21-40-30](https://user-images.githubusercontent.com/81166835/192161101-e722c8e6-e59a-4444-9c7f-3764c0fcc26a.png)

   - Шаг 4 На четвертой итерации отображаются значения параметров, значения потерь и эффекты визуализации

![2022-09-25_21-40-37](https://user-images.githubusercontent.com/81166835/192161105-6f12405c-4400-42ed-a58d-c950e5e16816.png)

   - Шаг 5 Пятая итерация показывает значение параметра, значение потерь и эффект визуализации после итерации

![2022-09-25_21-40-44](https://user-images.githubusercontent.com/81166835/192161113-16d818b7-b010-45e0-a502-665c999db1e3.png)

   - Шаг 6 10000-я итерация, показывающая значения параметров, потери и визуализацию после итерации

![2022-09-25_21-40-49](https://user-images.githubusercontent.com/81166835/192161121-2e4cd43f-304b-49e4-ab1d-ea7d7f1a767b.png)



## Задание 3
### Должна ли величина loss стремиться к нулю при изменении исходных данных? Ответьте на вопрос, приведите пример выполнения кода, который подтверждает ваш ответ.

Да, должна, так как с каждой итерацией модель постепенно "обучается". А соответственно функция потерь стремится к нулю.

1 итерация:

![2022-09-26_00-59-16](https://user-images.githubusercontent.com/81166835/192167517-3727216b-07e3-4456-a7ae-1bf0eb6902e9.png)

10000 итерация:

![2022-09-26_00-59-30](https://user-images.githubusercontent.com/81166835/192167506-35ab7bde-71be-49af-bfd3-27136d29c801.png)

### Какова роль параметра Lr? Ответьте на вопрос, приведите пример выполнения кода, который подтверждает ваш ответ. В качестве эксперимента можете изменить значение параметра.

Параметр Lr отвечает за "обучение" модели. Чем больше этот параметр, тем быстрее модель обучается, а значит функция потерь меньше

При Lr=0.000001, функция потерь практчески не уменьшилась
1 итерация:

![2022-09-26_01-45-18](https://user-images.githubusercontent.com/81166835/192169289-efb467c7-2e0d-4e84-8eba-01763b8c4ac5.png)

5 итерация:

![2022-09-26_01-46-23](https://user-images.githubusercontent.com/81166835/192169299-13c925ee-97a3-45e2-b089-2823efd67d6b.png)

При Lr=0.0001, функция потерь заметно уменьшилась, уже на второй итерации

1 итерация:

![2022-09-26_01-47-02](https://user-images.githubusercontent.com/81166835/192169350-44ed3f6c-d86c-4998-95bd-31901736937f.png)

2 итерация:

![2022-09-26_01-47-08](https://user-images.githubusercontent.com/81166835/192169356-0943f314-9ead-44c3-940c-a1f696d27ee2.png)

## Выводы

В ходе данной лабораторной работы я ознакомилась с основными операторами языка Python на примере реализации линейной регрессии. В первом задании был написан код для вывода фразы "Hello, World" на языке Python в сервисе Google.colab и на языке C# в VS Code, который был запущен в Unity. Во втором задании поработала с кодом, реализующим линейную регрессию. В третьем задании проанализировала код и сделала такие выводы: при уменьшении исходных данных уменьшается величина потерь, то есть стремится к нулю; параметр Lr отвечает за разницу значений после каждой итерации, чем больше значение Lr, тем больше разница между значениями.

| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
